{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from random import shuffle\n",
    "\n",
    "from shapely.geometry import LineString, mapping, shape, MultiPolygon\n",
    "from shapely.ops import polygonize, unary_union\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polygonfilename = 'annual.geojson' #input polygons\n",
    "fieldname_of_s1 = 'filename' #field with S1 filename associated with polygon\n",
    "fieldname_uuid = 'uuid' #field with uuid info\n",
    "\n",
    "# summary of script / introduction to user variables:\n",
    "\n",
    "# 1. estimation of all the fields' centroids\n",
    "# 2. form buffer around these centroids\n",
    "\n",
    "BUFFERSIZE_DEG = 0.18\n",
    "\n",
    "#3. check for intersections of these buffers and neighboring centroids; this corresponds to file lists as each buffer/centroid is associated with an acquisition\n",
    "#4. keep only supersets of the filelists to reduce computational demand\n",
    "#5. take a superset (e.g. 30 S1-scenes with each month present), and build all subsets of 12 scenes which cover every month\n",
    "#6. Estimate the size of overlap for SUBSET_PCT % of these files (greatly increases speed)\n",
    "\n",
    "SUBSET_PCT = 0.0005\n",
    "\n",
    "#7. create geojsons for best subsets\n",
    "\n",
    "schm = {'geometry': 'MultiPoint','properties': {fieldname_of_s1: 'str', fieldname_uuid: 'str'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### recursive function to split a list into sublists, i.e.:\n",
    "### purpose: [1,2a,2b,3] => [1,2a,3], [1,2b,3], just with S1 filenames in list concerning months\n",
    "### very quick, but:\n",
    "### fix input and return (right now depends on global variables:\n",
    "### \"fulllist, p, monthlies\")\n",
    "\n",
    "def recklist(liste=[], index=0):  \n",
    "    if index < len(fulllist):        \n",
    "        occurences = fulllist.count(fulllist[index])\n",
    "        for o in range(occurences):\n",
    "            newlist = liste[:]\n",
    "            newlist.append(p[index + o])\n",
    "            cont_here = len(fulllist) - fulllist[::-1].index(fulllist[index])\n",
    "            recklist(newlist[:], cont_here)            \n",
    "    else:\n",
    "        return monthlies.append(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "with fiona.open(polygonfilename) as layer:\n",
    "    all_centroid_shapes = []\n",
    "    all_buffer_shapes = []\n",
    "    all_properties = []\n",
    "    for p in layer:\n",
    "        all_centroid_shapes.append(shape(p['geometry']).centroid)\n",
    "        all_buffer_shapes.append(shape(p['geometry']).centroid.buffer(BUFFERSIZE_DEG))\n",
    "        all_properties.append({fieldname_of_s1: p['properties'][fieldname_of_s1]})\n",
    "        \n",
    "    # intersections is a dictionary\n",
    "    # each entry is the index of an element in centroids, combined with filenames\n",
    "    # of the scenes of the buffers it intersects..\n",
    "    \n",
    "    intersections = {}\n",
    "    \n",
    "    for j,c in enumerate(all_centroid_shapes):\n",
    "        intersections_sub = []\n",
    "        for i,b in enumerate(all_buffer_shapes):               \n",
    "            if c.intersects(b):\n",
    "                intersections_sub.append(all_properties[i][fieldname_of_s1])        \n",
    "        covered_months = []\n",
    "        for e in intersections_sub:\n",
    "            covered_months.append(e[21:23])\n",
    "        if len(set(covered_months)) == 12:\n",
    "            intersections[j] = set(intersections_sub)\n",
    "            \n",
    "    od = OrderedDict(sorted(intersections.items(), key=lambda t: t[0]))\n",
    "    \n",
    "  \n",
    "    maxid = od.keys()[-1]\n",
    "    while i != maxid:\n",
    "        hier = False\n",
    "        for i in od:\n",
    "            for j in od:\n",
    "                if od[i] <= od[j] and i != j:\n",
    "                    hier = i\n",
    "                    break\n",
    "            if hier == i:\n",
    "                break\n",
    "        if hier:\n",
    "            del(od[hier])\n",
    "    \n",
    "    best_stacks = []\n",
    "    best_areas = []\n",
    "    \n",
    "    for i in od:\n",
    "        p = list(od[i])\n",
    "        p.sort()\n",
    "        fulllist = [e[19:23] for e in p]\n",
    "        monthlies = []\n",
    "        # this generates all potential stacks of monthly\n",
    "        # coverage from a stack >= 12        \n",
    "        recklist()\n",
    "        \n",
    "        best_area = 0\n",
    "        \n",
    "        shuffle(monthlies)\n",
    "        n_to_check = int(SUBSET_PCT*len(monthlies))\n",
    "        \n",
    "        print n_to_check\n",
    "        \n",
    "        for j, m in enumerate(monthlies[:n_to_check]):\n",
    "            print j\n",
    "            fin_shape = shape(filter(lambda f: f['properties'][fieldname_of_s1]==m[0], layer)[0]['geometry'])\n",
    "            for n in m[1:]:      \n",
    "                new_shape = shape(filter(lambda f: f['properties'][fieldname_of_s1]==n, layer)[0]['geometry'])\n",
    "                fin_shape = fin_shape.intersection(new_shape)\n",
    "            \n",
    "            area = fin_shape.area\n",
    "            if area > best_area:\n",
    "                best_stack = m\n",
    "                best_area = area\n",
    "        \n",
    "        best_stacks.append(best_stack)\n",
    "        best_areas.append(best_area)\n",
    "        \n",
    "    \n",
    "    i=0     \n",
    "    for a, supset in enumerate(best_stacks):\n",
    "        with fiona.open('4suggestion_'+str(i)+'_witharea_'+str(best_areas[a])+'.geojson', 'w', 'GeoJSON', schm) as tgt: \n",
    "            for swath_outline in supset:\n",
    "                fin_shape = shape(filter(lambda f: f['properties'][fieldname_of_s1]==swath_outline, layer)[0]['geometry'])\n",
    "                uuid_here = filter(lambda f: f['properties'][fieldname_of_s1]==swath_outline, layer)[0]['properties']['uuid']\n",
    "                tgt.write({'geometry': mapping(fin_shape), 'properties': {fieldname_of_s1:str(swath_outline), fieldname_uuid:str(uuid_here)}})\n",
    "        i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
